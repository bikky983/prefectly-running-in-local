name: Automated Nepali News Posts

on:
  schedule:
    # Run at 10:00 AM Nepal Time (04:15 UTC) - Morning news
    - cron: '15 4 * * *'
    # Run at 1:00 PM Nepal Time (07:15 UTC) - Afternoon news
    - cron: '15 7 * * *'
    # Run at 4:00 PM Nepal Time (10:15 UTC) - Evening news
    - cron: '15 10 * * *'
    # Run at 7:00 PM Nepal Time (13:15 UTC) - Night news
    - cron: '15 13 * * *'
  
  workflow_dispatch:  # Allow manual trigger for testing
    inputs:
      time_slot:
        description: 'Time slot to run'
        required: false
        default: 'all'
        type: choice
        options:
          - morning
          - afternoon
          - evening
          - night
          - all

env:
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
  DEEPSEEK_API_URL: https://openrouter.ai/api/v1/chat/completions
  DEEPSEEK_MODEL: deepseek/deepseek-chat
  RCLONE_CONFIG: ${{ secrets.RCLONE_CONFIG }}
  # Social Media API Keys
  FACEBOOK_ACCESS_TOKEN: ${{ secrets.FACEBOOK_ACCESS_TOKEN }}
  FACEBOOK_PAGE_ID: ${{ secrets.FACEBOOK_PAGE_ID }}
  INSTAGRAM_ACCESS_TOKEN: ${{ secrets.INSTAGRAM_ACCESS_TOKEN }}
  INSTAGRAM_USER_ID: ${{ secrets.INSTAGRAM_USER_ID }}

jobs:
  generate-news-posts:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Install Playwright browsers
        run: |
          playwright install chromium
          playwright install-deps chromium
      
      - name: Install Rclone
        run: |
          curl -O https://downloads.rclone.org/rclone-current-linux-amd64.zip
          unzip rclone-current-linux-amd64.zip
          sudo cp rclone-*-linux-amd64/rclone /usr/bin/
          sudo chown root:root /usr/bin/rclone
          sudo chmod 755 /usr/bin/rclone
          rclone version
      
      - name: Clean up old files from previous runs
        run: |
          echo "ðŸ§¹ Cleaning up old files to ensure fresh news..."
          rm -f multi_source_links.json
          rm -f multi_source_articles.json
          rm -f multi_source_summaries.json
          rm -rf output/
          echo "âœ… Cleanup complete"
      
      - name: Determine time slot
        id: timeslot
        run: |
          HOUR=$(TZ='Asia/Kathmandu' date +%H)
          if [ "$HOUR" -ge 4 ] && [ "$HOUR" -lt 11 ]; then
            echo "slot=morning" >> $GITHUB_OUTPUT
            echo "time_range=10:00 AM" >> $GITHUB_OUTPUT
          elif [ "$HOUR" -ge 11 ] && [ "$HOUR" -lt 14 ]; then
            echo "slot=afternoon" >> $GITHUB_OUTPUT
            echo "time_range=1:00 PM" >> $GITHUB_OUTPUT
          elif [ "$HOUR" -ge 14 ] && [ "$HOUR" -lt 17 ]; then
            echo "slot=evening" >> $GITHUB_OUTPUT
            echo "time_range=4:00 PM" >> $GITHUB_OUTPUT
          else
            echo "slot=night" >> $GITHUB_OUTPUT
            echo "time_range=7:00 PM" >> $GITHUB_OUTPUT
          fi
      
      - name: Run news scraping and summarization
        run: |
          echo "ðŸ” Scraping ${{ steps.timeslot.outputs.time_range }} news..."
          python main.py
        env:
          PYTHONUNBUFFERED: 1
      
      - name: Validate fresh news data
        run: |
          echo "ðŸ” Validating that we have fresh news data..."
          
          # Check if summaries file exists
          if [ ! -f "multi_source_summaries.json" ]; then
            echo "âŒ ERROR: multi_source_summaries.json not found!"
            echo "News scraping or summarization failed. Cannot proceed."
            exit 1
          fi
          
          # Check if file is not empty
          if [ ! -s "multi_source_summaries.json" ]; then
            echo "âŒ ERROR: multi_source_summaries.json is empty!"
            exit 1
          fi
          
          # Check if file was just created (within last 10 minutes)
          FILE_AGE=$(( $(date +%s) - $(stat -c %Y multi_source_summaries.json 2>/dev/null || stat -f %m multi_source_summaries.json) ))
          if [ $FILE_AGE -gt 600 ]; then
            echo "âŒ ERROR: multi_source_summaries.json is too old (${FILE_AGE}s)!"
            echo "This file was not freshly generated in this run."
            exit 1
          fi
          
          echo "âœ… Fresh news data validated (age: ${FILE_AGE}s)"
      
      - name: Generate social media posts
        run: |
          echo "ðŸŽ¨ Generating social media posts..."
          python -m src.generate_posts_playwright --force
        env:
          PYTHONUNBUFFERED: 1
      
      - name: Validate Social Media Tokens
        run: |
          echo "ðŸ” Validating Facebook and Instagram tokens..."
          python scripts/token_manager.py
        env:
          PYTHONUNBUFFERED: 1
        continue-on-error: true
      
      - name: Post to Social Media
        run: |
          echo "ðŸ“± Posting to Facebook and Instagram..."
          python scripts/post_to_social.py
        env:
          PYTHONUNBUFFERED: 1
      
      - name: Upload to Google Drive
        run: |
          echo "ðŸ“¤ Uploading images to Google Drive..."
          python scripts/upload_to_gdrive.py
        env:
          PYTHONUNBUFFERED: 1
      
      - name: Get current timestamp
        id: timestamp
        run: |
          echo "datetime=$(TZ='Asia/Kathmandu' date +'%Y-%m-%d_%H-%M')" >> $GITHUB_OUTPUT
          echo "readable=$(TZ='Asia/Kathmandu' date +'%Y-%m-%d %I:%M %p NPT')" >> $GITHUB_OUTPUT
      
      - name: Upload generated posts
        uses: actions/upload-artifact@v4
        with:
          name: news-posts-${{ steps.timeslot.outputs.slot }}-${{ steps.timestamp.outputs.datetime }}
          path: |
            output/*.png
            multi_source_summaries.json
            multi_source_articles.json
            multi_source_links.json
          retention-days: 30
      
      - name: Commit and push generated files (optional)
        if: github.event_name == 'schedule'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Create timestamped directory for this run
          mkdir -p archives/${{ steps.timeslot.outputs.slot }}/${{ steps.timestamp.outputs.datetime }}
          
          # Copy generated files
          cp output/*.png archives/${{ steps.timeslot.outputs.slot }}/${{ steps.timestamp.outputs.datetime }}/ || true
          cp multi_source_summaries.json archives/${{ steps.timeslot.outputs.slot }}/${{ steps.timestamp.outputs.datetime }}/ || true
          
          # Commit the post tracker to persist between runs (prevents duplicate posts)
          git add posted_articles.json || true
          
          # Add and commit
          git add archives/
          git commit -m "ðŸ“° Auto-generated news posts - ${{ steps.timeslot.outputs.slot }} (${{ steps.timestamp.outputs.readable }})" || echo "No changes to commit"
          git push || echo "Nothing to push"
      
      - name: Create summary
        run: |
          echo "## ðŸ“° Automated Nepali News Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Time Slot**: ${{ steps.timeslot.outputs.slot }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Time Range**: ${{ steps.timeslot.outputs.time_range }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Generated At**: ${{ steps.timestamp.outputs.readable }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f multi_source_summaries.json ]; then
            ARTICLE_COUNT=$(python -c "import json; print(len(json.load(open('multi_source_summaries.json'))))")
            echo "- **Articles Processed**: $ARTICLE_COUNT" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -d output ]; then
            POST_COUNT=$(ls -1 output/*.png 2>/dev/null | wc -l)
            echo "- **Posts Generated**: $POST_COUNT" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸš€ Automation Steps Completed:" >> $GITHUB_STEP_SUMMARY
          echo "1. âœ… **News Scraping** - Multi-source article collection" >> $GITHUB_STEP_SUMMARY
          echo "2. âœ… **Content Extraction** - Clean Nepali text extraction" >> $GITHUB_STEP_SUMMARY
          echo "3. âœ… **AI Summarization** - DeepSeek LLM processing" >> $GITHUB_STEP_SUMMARY
          echo "4. âœ… **Post Generation** - Beautiful social media images" >> $GITHUB_STEP_SUMMARY
          echo "5. âœ… **Social Media Posting** - Facebook & Instagram" >> $GITHUB_STEP_SUMMARY
          echo "6. âœ… **Google Drive Upload** - Organized cloud storage" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸŽ‰ **Status**: Complete Automation Success!" >> $GITHUB_STEP_SUMMARY
